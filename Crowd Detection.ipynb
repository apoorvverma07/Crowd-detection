{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QKWqMply7GC5",
        "outputId": "f871c8a0-9cbe-49e4-da97-0b415818d4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.36-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.36-py3-none-any.whl (887 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.3/887.3 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.36 ultralytics-thop-2.0.12\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FegS_iK7LWd",
        "outputId": "318fba94-ceb6-46b2-ae89-c0b20d60c778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131M/131M [00:00<00:00, 334MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 35 persons, 4 handbags, 1 frisbee, 1 clock, 214.4ms\n",
            "Speed: 26.0ms preprocess, 214.4ms inference, 738.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 2 handbags, 1 frisbee, 1 tennis racket, 53.8ms\n",
            "Speed: 3.1ms preprocess, 53.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 2 handbags, 1 frisbee, 1 tennis racket, 53.7ms\n",
            "Speed: 3.1ms preprocess, 53.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 2 handbags, 2 frisbees, 1 tennis racket, 53.8ms\n",
            "Speed: 3.2ms preprocess, 53.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 2 frisbees, 41.6ms\n",
            "Speed: 2.7ms preprocess, 41.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 2 frisbees, 41.7ms\n",
            "Speed: 3.0ms preprocess, 41.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 1 frisbee, 40.3ms\n",
            "Speed: 3.2ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 2 handbags, 2 frisbees, 31.6ms\n",
            "Speed: 3.3ms preprocess, 31.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 1 handbag, 1 frisbee, 32.1ms\n",
            "Speed: 4.7ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 1 handbag, 2 frisbees, 31.3ms\n",
            "Speed: 2.9ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 1 handbag, 2 frisbees, 31.4ms\n",
            "Speed: 3.2ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 1 handbag, 1 frisbee, 31.5ms\n",
            "Speed: 3.2ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 2 handbags, 1 frisbee, 30.6ms\n",
            "Speed: 3.2ms preprocess, 30.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 backpacks, 3 handbags, 1 frisbee, 30.4ms\n",
            "Speed: 3.3ms preprocess, 30.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 backpacks, 2 handbags, 1 frisbee, 30.6ms\n",
            "Speed: 4.5ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 3 handbags, 1 frisbee, 29.6ms\n",
            "Speed: 3.8ms preprocess, 29.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 backpacks, 1 handbag, 2 frisbees, 29.5ms\n",
            "Speed: 6.4ms preprocess, 29.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 2 handbags, 2 frisbees, 30.6ms\n",
            "Speed: 3.2ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 6 backpacks, 1 handbag, 1 frisbee, 29.7ms\n",
            "Speed: 3.6ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 1 handbag, 1 frisbee, 30.5ms\n",
            "Speed: 3.2ms preprocess, 30.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 2 backpacks, 1 frisbee, 29.4ms\n",
            "Speed: 3.2ms preprocess, 29.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 1 frisbee, 29.4ms\n",
            "Speed: 3.2ms preprocess, 29.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 backpacks, 1 handbag, 1 frisbee, 30.5ms\n",
            "Speed: 3.5ms preprocess, 30.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 1 handbag, 29.9ms\n",
            "Speed: 4.3ms preprocess, 29.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 1 handbag, 30.4ms\n",
            "Speed: 3.5ms preprocess, 30.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 backpacks, 1 handbag, 1 tennis racket, 30.5ms\n",
            "Speed: 3.3ms preprocess, 30.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 backpacks, 3 handbags, 1 tennis racket, 30.3ms\n",
            "Speed: 3.2ms preprocess, 30.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 backpacks, 2 handbags, 1 tennis racket, 29.7ms\n",
            "Speed: 3.3ms preprocess, 29.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 backpacks, 1 handbag, 1 tennis racket, 30.6ms\n",
            "Speed: 3.8ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 backpacks, 1 handbag, 1 tennis racket, 29.8ms\n",
            "Speed: 3.1ms preprocess, 29.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 backpacks, 1 handbag, 1 tennis racket, 31.2ms\n",
            "Speed: 3.2ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 4 backpacks, 30.5ms\n",
            "Speed: 3.2ms preprocess, 30.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 31.2ms\n",
            "Speed: 4.3ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 1 tennis racket, 30.5ms\n",
            "Speed: 3.2ms preprocess, 30.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 backpacks, 1 tennis racket, 30.5ms\n",
            "Speed: 3.2ms preprocess, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 backpacks, 1 skis, 30.2ms\n",
            "Speed: 4.3ms preprocess, 30.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 6 backpacks, 1 handbag, 30.5ms\n",
            "Speed: 3.3ms preprocess, 30.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 6 backpacks, 1 tennis racket, 29.7ms\n",
            "Speed: 3.1ms preprocess, 29.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 1 handbag, 30.5ms\n",
            "Speed: 3.6ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 3 handbags, 29.8ms\n",
            "Speed: 3.2ms preprocess, 29.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 3 backpacks, 3 handbags, 30.5ms\n",
            "Speed: 2.9ms preprocess, 30.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 1 handbag, 30.6ms\n",
            "Speed: 2.9ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 4 backpacks, 1 handbag, 1 tennis racket, 29.9ms\n",
            "Speed: 4.1ms preprocess, 29.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 4 backpacks, 1 tennis racket, 29.9ms\n",
            "Speed: 3.3ms preprocess, 29.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 4 backpacks, 1 tennis racket, 30.4ms\n",
            "Speed: 4.0ms preprocess, 30.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 5 backpacks, 1 handbag, 2 tennis rackets, 30.5ms\n",
            "Speed: 3.9ms preprocess, 30.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 6 backpacks, 1 tennis racket, 30.4ms\n",
            "Speed: 3.9ms preprocess, 30.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 4 backpacks, 1 handbag, 1 tennis racket, 30.4ms\n",
            "Speed: 4.3ms preprocess, 30.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 4 backpacks, 2 handbags, 1 tennis racket, 30.6ms\n",
            "Speed: 3.3ms preprocess, 30.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 4 backpacks, 2 handbags, 30.7ms\n",
            "Speed: 4.5ms preprocess, 30.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 backpacks, 2 handbags, 30.2ms\n",
            "Speed: 3.2ms preprocess, 30.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 5 backpacks, 1 handbag, 30.1ms\n",
            "Speed: 3.1ms preprocess, 30.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 4 backpacks, 2 handbags, 30.3ms\n",
            "Speed: 3.4ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 1 handbag, 1 tennis racket, 30.5ms\n",
            "Speed: 3.5ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 6 backpacks, 1 handbag, 1 tennis racket, 30.0ms\n",
            "Speed: 3.4ms preprocess, 30.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 2 handbags, 1 tennis racket, 30.5ms\n",
            "Speed: 3.3ms preprocess, 30.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 4 backpacks, 1 handbag, 29.6ms\n",
            "Speed: 3.1ms preprocess, 29.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 1 handbag, 1 frisbee, 1 tennis racket, 30.1ms\n",
            "Speed: 4.5ms preprocess, 30.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 6 backpacks, 1 handbag, 1 frisbee, 30.6ms\n",
            "Speed: 3.3ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 5 backpacks, 2 handbags, 29.7ms\n",
            "Speed: 3.2ms preprocess, 29.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 4 backpacks, 1 handbag, 30.8ms\n",
            "Speed: 3.1ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 5 backpacks, 1 handbag, 30.2ms\n",
            "Speed: 3.2ms preprocess, 30.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 5 backpacks, 2 handbags, 1 frisbee, 30.1ms\n",
            "Speed: 3.4ms preprocess, 30.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 backpacks, 2 handbags, 1 frisbee, 30.0ms\n",
            "Speed: 4.0ms preprocess, 30.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 5 backpacks, 2 handbags, 1 frisbee, 30.7ms\n",
            "Speed: 3.4ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 4 backpacks, 2 handbags, 1 frisbee, 30.7ms\n",
            "Speed: 3.4ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 backpacks, 2 handbags, 1 frisbee, 29.7ms\n",
            "Speed: 3.4ms preprocess, 29.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 backpacks, 3 handbags, 1 frisbee, 30.4ms\n",
            "Speed: 6.5ms preprocess, 30.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 5 backpacks, 2 handbags, 30.3ms\n",
            "Speed: 3.1ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 backpacks, 2 handbags, 1 frisbee, 30.3ms\n",
            "Speed: 3.2ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 backpacks, 2 handbags, 1 frisbee, 30.3ms\n",
            "Speed: 4.1ms preprocess, 30.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 backpacks, 2 handbags, 1 frisbee, 30.3ms\n",
            "Speed: 3.2ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 2 handbags, 1 frisbee, 30.4ms\n",
            "Speed: 3.6ms preprocess, 30.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 backpacks, 1 handbag, 1 frisbee, 30.5ms\n",
            "Speed: 3.5ms preprocess, 30.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 backpacks, 1 handbag, 1 frisbee, 29.4ms\n",
            "Speed: 3.4ms preprocess, 29.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 backpacks, 1 handbag, 1 frisbee, 32.3ms\n",
            "Speed: 3.7ms preprocess, 32.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 4 backpacks, 2 handbags, 29.5ms\n",
            "Speed: 4.4ms preprocess, 29.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 backpacks, 2 handbags, 29.6ms\n",
            "Speed: 3.4ms preprocess, 29.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 backpacks, 1 handbag, 30.6ms\n",
            "Speed: 3.2ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 1 backpack, 2 handbags, 29.6ms\n",
            "Speed: 3.3ms preprocess, 29.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 4 backpacks, 2 handbags, 1 tennis racket, 30.6ms\n",
            "Speed: 3.3ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 2 backpacks, 1 tennis racket, 30.7ms\n",
            "Speed: 3.6ms preprocess, 30.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 3 backpacks, 1 tennis racket, 29.4ms\n",
            "Speed: 4.8ms preprocess, 29.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 6 backpacks, 1 handbag, 1 tennis racket, 35.5ms\n",
            "Speed: 2.9ms preprocess, 35.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 2 backpacks, 1 tennis racket, 31.7ms\n",
            "Speed: 3.4ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 3 backpacks, 1 tennis racket, 31.3ms\n",
            "Speed: 3.7ms preprocess, 31.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 4 backpacks, 1 tennis racket, 30.4ms\n",
            "Speed: 3.1ms preprocess, 30.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 4 backpacks, 1 handbag, 1 frisbee, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 4 backpacks, 1 handbag, 32.2ms\n",
            "Speed: 3.5ms preprocess, 32.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 1 handbag, 31.8ms\n",
            "Speed: 3.5ms preprocess, 31.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 31.9ms\n",
            "Speed: 3.6ms preprocess, 31.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 1 handbag, 1 suitcase, 30.0ms\n",
            "Speed: 6.1ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 3 backpacks, 1 handbag, 30.0ms\n",
            "Speed: 5.3ms preprocess, 30.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 3 backpacks, 1 handbag, 30.7ms\n",
            "Speed: 3.3ms preprocess, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 3 backpacks, 1 handbag, 30.8ms\n",
            "Speed: 3.3ms preprocess, 30.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 1 handbag, 1 suitcase, 29.6ms\n",
            "Speed: 3.2ms preprocess, 29.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 2 handbags, 29.9ms\n",
            "Speed: 3.2ms preprocess, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 2 handbags, 29.8ms\n",
            "Speed: 3.2ms preprocess, 29.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 backpacks, 2 handbags, 29.1ms\n",
            "Speed: 3.7ms preprocess, 29.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 2 handbags, 30.0ms\n",
            "Speed: 5.1ms preprocess, 30.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 1 handbag, 29.6ms\n",
            "Speed: 6.2ms preprocess, 29.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 backpacks, 1 handbag, 90.2ms\n",
            "Speed: 3.2ms preprocess, 90.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 backpacks, 1 handbag, 51.6ms\n",
            "Speed: 3.3ms preprocess, 51.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 1 handbag, 29.4ms\n",
            "Speed: 3.2ms preprocess, 29.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 1 handbag, 29.3ms\n",
            "Speed: 3.1ms preprocess, 29.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 backpacks, 1 handbag, 29.9ms\n",
            "Speed: 7.2ms preprocess, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 backpacks, 2 handbags, 32.2ms\n",
            "Speed: 3.0ms preprocess, 32.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 36.9ms\n",
            "Speed: 3.2ms preprocess, 36.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 36.9ms\n",
            "Speed: 3.3ms preprocess, 36.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 1 handbag, 38.7ms\n",
            "Speed: 3.1ms preprocess, 38.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 1 handbag, 35.9ms\n",
            "Speed: 3.2ms preprocess, 35.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 35.9ms\n",
            "Speed: 3.5ms preprocess, 35.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 2 handbags, 36.9ms\n",
            "Speed: 6.2ms preprocess, 36.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 1 handbag, 36.8ms\n",
            "Speed: 3.1ms preprocess, 36.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 1 handbag, 1 suitcase, 35.9ms\n",
            "Speed: 3.2ms preprocess, 35.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 2 handbags, 35.9ms\n",
            "Speed: 3.2ms preprocess, 35.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 backpacks, 2 handbags, 38.1ms\n",
            "Speed: 3.7ms preprocess, 38.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 4 backpacks, 2 handbags, 36.0ms\n",
            "Speed: 3.4ms preprocess, 36.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 2 handbags, 35.9ms\n",
            "Speed: 6.2ms preprocess, 35.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 1 handbag, 35.9ms\n",
            "Speed: 3.2ms preprocess, 35.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 35.9ms\n",
            "Speed: 2.9ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 36.8ms\n",
            "Speed: 3.4ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 1 handbag, 32.6ms\n",
            "Speed: 3.4ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 1 handbag, 32.2ms\n",
            "Speed: 3.4ms preprocess, 32.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 2 handbags, 32.6ms\n",
            "Speed: 3.3ms preprocess, 32.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 1 handbag, 1 frisbee, 29.6ms\n",
            "Speed: 3.2ms preprocess, 29.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 2 handbags, 29.9ms\n",
            "Speed: 6.3ms preprocess, 29.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 3 handbags, 30.7ms\n",
            "Speed: 3.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 1 handbag, 30.8ms\n",
            "Speed: 3.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 30.9ms\n",
            "Speed: 3.5ms preprocess, 30.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 31.2ms\n",
            "Speed: 3.0ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 2 handbags, 1 tennis racket, 30.4ms\n",
            "Speed: 3.0ms preprocess, 30.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 3 handbags, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 1 handbag, 30.5ms\n",
            "Speed: 3.5ms preprocess, 30.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 3 handbags, 30.4ms\n",
            "Speed: 3.6ms preprocess, 30.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 30.8ms\n",
            "Speed: 3.4ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 3 handbags, 29.9ms\n",
            "Speed: 3.3ms preprocess, 29.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 30.3ms\n",
            "Speed: 6.3ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 1 handbag, 30.3ms\n",
            "Speed: 3.6ms preprocess, 30.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 backpacks, 3 handbags, 30.7ms\n",
            "Speed: 3.2ms preprocess, 30.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 3 handbags, 30.0ms\n",
            "Speed: 3.3ms preprocess, 30.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 2 handbags, 1 frisbee, 30.7ms\n",
            "Speed: 3.0ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 backpacks, 3 handbags, 29.9ms\n",
            "Speed: 3.2ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 backpacks, 3 handbags, 30.5ms\n",
            "Speed: 6.9ms preprocess, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 backpacks, 3 handbags, 30.5ms\n",
            "Speed: 3.3ms preprocess, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 backpacks, 2 handbags, 1 frisbee, 29.9ms\n",
            "Speed: 2.9ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 1 tennis racket, 30.8ms\n",
            "Speed: 2.9ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 1 tennis racket, 29.9ms\n",
            "Speed: 3.3ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 1 tennis racket, 30.7ms\n",
            "Speed: 3.2ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 handbag, 1 tennis racket, 30.7ms\n",
            "Speed: 3.1ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 handbag, 1 tennis racket, 31.4ms\n",
            "Speed: 3.4ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 tennis racket, 31.4ms\n",
            "Speed: 3.6ms preprocess, 31.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 handbag, 1 suitcase, 2 tennis rackets, 30.7ms\n",
            "Speed: 3.8ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 3 handbags, 1 suitcase, 2 tennis rackets, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 handbag, 1 suitcase, 2 tennis rackets, 30.1ms\n",
            "Speed: 3.2ms preprocess, 30.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 1 suitcase, 2 tennis rackets, 30.5ms\n",
            "Speed: 3.3ms preprocess, 30.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 backpacks, 3 handbags, 1 tennis racket, 30.8ms\n",
            "Speed: 3.4ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 backpacks, 2 handbags, 1 suitcase, 1 tennis racket, 29.7ms\n",
            "Speed: 4.2ms preprocess, 29.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 1 handbag, 29.4ms\n",
            "Speed: 5.1ms preprocess, 29.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 30.8ms\n",
            "Speed: 3.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 1 tennis racket, 29.6ms\n",
            "Speed: 3.6ms preprocess, 29.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 2 handbags, 30.7ms\n",
            "Speed: 3.1ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 1 handbag, 1 frisbee, 30.8ms\n",
            "Speed: 3.4ms preprocess, 30.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 3 handbags, 30.2ms\n",
            "Speed: 3.5ms preprocess, 30.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 2 handbags, 1 tennis racket, 30.7ms\n",
            "Speed: 3.4ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 2 handbags, 1 tennis racket, 29.9ms\n",
            "Speed: 3.4ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 2 handbags, 1 tennis racket, 29.9ms\n",
            "Speed: 3.3ms preprocess, 29.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 2 handbags, 1 tennis racket, 30.8ms\n",
            "Speed: 3.4ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 backpacks, 3 handbags, 30.4ms\n",
            "Speed: 3.1ms preprocess, 30.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 3 handbags, 30.7ms\n",
            "Speed: 3.4ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 30.0ms\n",
            "Speed: 2.9ms preprocess, 30.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 3 handbags, 29.4ms\n",
            "Speed: 3.1ms preprocess, 29.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 4 handbags, 30.4ms\n",
            "Speed: 3.1ms preprocess, 30.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 3 handbags, 30.8ms\n",
            "Speed: 5.0ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 30.0ms\n",
            "Speed: 3.1ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 1 handbag, 30.5ms\n",
            "Speed: 3.1ms preprocess, 30.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 1 handbag, 30.8ms\n",
            "Speed: 3.5ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 30.0ms\n",
            "Speed: 3.9ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 1 handbag, 30.8ms\n",
            "Speed: 3.1ms preprocess, 30.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 1 handbag, 1 tennis racket, 31.0ms\n",
            "Speed: 3.3ms preprocess, 31.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 1 handbag, 30.9ms\n",
            "Speed: 3.1ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 30.2ms\n",
            "Speed: 2.9ms preprocess, 30.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 2 handbags, 30.9ms\n",
            "Speed: 2.9ms preprocess, 30.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 30.8ms\n",
            "Speed: 3.2ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 2 handbags, 30.7ms\n",
            "Speed: 3.3ms preprocess, 30.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 1 handbag, 30.9ms\n",
            "Speed: 4.1ms preprocess, 30.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 29.9ms\n",
            "Speed: 3.5ms preprocess, 29.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 1 handbag, 29.4ms\n",
            "Speed: 4.3ms preprocess, 29.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 1 handbag, 30.9ms\n",
            "Speed: 3.1ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 1 handbag, 31.0ms\n",
            "Speed: 4.1ms preprocess, 31.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 1 handbag, 31.6ms\n",
            "Speed: 3.7ms preprocess, 31.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 30.9ms\n",
            "Speed: 5.0ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 3 handbags, 31.3ms\n",
            "Speed: 3.4ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 2 handbags, 32.0ms\n",
            "Speed: 3.6ms preprocess, 32.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 3 handbags, 32.1ms\n",
            "Speed: 3.4ms preprocess, 32.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 4 handbags, 32.4ms\n",
            "Speed: 4.6ms preprocess, 32.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 2 handbags, 30.2ms\n",
            "Speed: 3.4ms preprocess, 30.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 2 handbags, 29.5ms\n",
            "Speed: 5.3ms preprocess, 29.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 5 backpacks, 2 handbags, 29.4ms\n",
            "Speed: 3.3ms preprocess, 29.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 2 handbags, 29.4ms\n",
            "Speed: 3.5ms preprocess, 29.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 4 handbags, 30.9ms\n",
            "Speed: 3.6ms preprocess, 30.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 1 handbag, 29.6ms\n",
            "Speed: 2.1ms preprocess, 29.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 1 handbag, 29.6ms\n",
            "Speed: 3.4ms preprocess, 29.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 1 handbag, 30.7ms\n",
            "Speed: 5.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 2 handbags, 30.1ms\n",
            "Speed: 3.2ms preprocess, 30.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 3 handbags, 30.9ms\n",
            "Speed: 3.1ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 3 handbags, 30.0ms\n",
            "Speed: 3.6ms preprocess, 30.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 1 handbag, 1 tennis racket, 29.4ms\n",
            "Speed: 3.3ms preprocess, 29.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 1 handbag, 1 tennis racket, 30.6ms\n",
            "Speed: 3.3ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 1 handbag, 1 tennis racket, 29.6ms\n",
            "Speed: 3.2ms preprocess, 29.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 3 handbags, 1 tennis racket, 29.7ms\n",
            "Speed: 3.4ms preprocess, 29.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 4 handbags, 1 tennis racket, 29.5ms\n",
            "Speed: 4.0ms preprocess, 29.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 3 handbags, 1 tennis racket, 32.7ms\n",
            "Speed: 3.6ms preprocess, 32.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 2 handbags, 1 tennis racket, 30.6ms\n",
            "Speed: 7.4ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 3 handbags, 30.2ms\n",
            "Speed: 3.2ms preprocess, 30.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 2 handbags, 1 frisbee, 30.2ms\n",
            "Speed: 3.2ms preprocess, 30.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 2 handbags, 1 frisbee, 1 tennis racket, 30.7ms\n",
            "Speed: 4.1ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 3 handbags, 1 frisbee, 1 tennis racket, 30.1ms\n",
            "Speed: 3.9ms preprocess, 30.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 3 handbags, 1 frisbee, 1 tennis racket, 30.5ms\n",
            "Speed: 3.1ms preprocess, 30.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 1 handbag, 1 suitcase, 1 frisbee, 30.5ms\n",
            "Speed: 3.0ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 3 handbags, 1 frisbee, 30.7ms\n",
            "Speed: 3.1ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 3 handbags, 1 frisbee, 30.8ms\n",
            "Speed: 3.6ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 2 handbags, 1 frisbee, 1 tennis racket, 30.0ms\n",
            "Speed: 7.5ms preprocess, 30.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 3 handbags, 30.7ms\n",
            "Speed: 3.0ms preprocess, 30.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 3 handbags, 30.0ms\n",
            "Speed: 3.4ms preprocess, 30.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 3 handbags, 29.9ms\n",
            "Speed: 4.0ms preprocess, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 3 handbags, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 3 handbags, 30.8ms\n",
            "Speed: 3.0ms preprocess, 30.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 2 handbags, 30.3ms\n",
            "Speed: 3.1ms preprocess, 30.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 1 tennis racket, 31.0ms\n",
            "Speed: 4.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 2 handbags, 1 tennis racket, 29.8ms\n",
            "Speed: 3.9ms preprocess, 29.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 3 handbags, 30.8ms\n",
            "Speed: 3.1ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 2 handbags, 1 tennis racket, 30.3ms\n",
            "Speed: 4.5ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 backpacks, 1 handbag, 1 frisbee, 1 tennis racket, 31.1ms\n",
            "Speed: 3.5ms preprocess, 31.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 3 handbags, 1 frisbee, 1 tennis racket, 30.4ms\n",
            "Speed: 4.3ms preprocess, 30.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 3 handbags, 1 frisbee, 1 tennis racket, 30.6ms\n",
            "Speed: 4.1ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 6 handbags, 1 frisbee, 1 tennis racket, 31.0ms\n",
            "Speed: 3.4ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 6 handbags, 1 frisbee, 1 tennis racket, 30.4ms\n",
            "Speed: 3.8ms preprocess, 30.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 5 handbags, 1 frisbee, 1 tennis racket, 29.6ms\n",
            "Speed: 4.5ms preprocess, 29.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 5 handbags, 1 frisbee, 1 tennis racket, 30.3ms\n",
            "Speed: 4.3ms preprocess, 30.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 4 handbags, 1 tennis racket, 29.7ms\n",
            "Speed: 5.2ms preprocess, 29.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 backpacks, 2 handbags, 1 tennis racket, 29.4ms\n",
            "Speed: 4.5ms preprocess, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 3 backpacks, 3 handbags, 1 tennis racket, 29.5ms\n",
            "Speed: 4.7ms preprocess, 29.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 backpacks, 3 handbags, 1 tennis racket, 29.3ms\n",
            "Speed: 3.1ms preprocess, 29.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 backpacks, 2 handbags, 1 tennis racket, 29.4ms\n",
            "Speed: 3.2ms preprocess, 29.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 2 backpacks, 3 handbags, 1 tennis racket, 34.4ms\n",
            "Speed: 3.3ms preprocess, 34.4ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 backpacks, 1 handbag, 1 tennis racket, 29.0ms\n",
            "Speed: 3.2ms preprocess, 29.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 1 handbag, 1 tennis racket, 29.3ms\n",
            "Speed: 3.2ms preprocess, 29.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 backpacks, 2 handbags, 1 tennis racket, 30.2ms\n",
            "Speed: 4.1ms preprocess, 30.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 backpacks, 3 handbags, 29.8ms\n",
            "Speed: 5.2ms preprocess, 29.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 backpacks, 4 handbags, 1 frisbee, 1 tennis racket, 30.6ms\n",
            "Speed: 3.8ms preprocess, 30.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 5 handbags, 1 tennis racket, 33.5ms\n",
            "Speed: 5.0ms preprocess, 33.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 4 handbags, 29.9ms\n",
            "Speed: 5.0ms preprocess, 29.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 5 handbags, 36.7ms\n",
            "Speed: 3.2ms preprocess, 36.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 5 handbags, 1 tennis racket, 30.3ms\n",
            "Speed: 4.6ms preprocess, 30.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 backpacks, 4 handbags, 1 frisbee, 28.9ms\n",
            "Speed: 3.8ms preprocess, 28.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 5 handbags, 1 frisbee, 1 tennis racket, 30.5ms\n",
            "Speed: 3.1ms preprocess, 30.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 backpacks, 5 handbags, 1 frisbee, 1 tennis racket, 33.3ms\n",
            "Speed: 3.3ms preprocess, 33.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 7 handbags, 1 frisbee, 1 tennis racket, 36.2ms\n",
            "Speed: 10.6ms preprocess, 36.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 backpacks, 5 handbags, 1 tennis racket, 34.5ms\n",
            "Speed: 6.8ms preprocess, 34.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 6 handbags, 1 frisbee, 1 tennis racket, 35.2ms\n",
            "Speed: 3.4ms preprocess, 35.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 5 handbags, 1 frisbee, 1 tennis racket, 37.2ms\n",
            "Speed: 3.4ms preprocess, 37.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 4 backpacks, 3 handbags, 1 tennis racket, 37.5ms\n",
            "Speed: 6.1ms preprocess, 37.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 5 backpacks, 3 handbags, 1 frisbee, 1 tennis racket, 44.2ms\n",
            "Speed: 3.3ms preprocess, 44.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 backpacks, 4 handbags, 1 frisbee, 1 tennis racket, 35.5ms\n",
            "Speed: 3.4ms preprocess, 35.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 3 handbags, 1 frisbee, 1 tennis racket, 38.8ms\n",
            "Speed: 4.3ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 3 handbags, 36.6ms\n",
            "Speed: 3.2ms preprocess, 36.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 4 backpacks, 4 handbags, 35.2ms\n",
            "Speed: 6.6ms preprocess, 35.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 backpacks, 3 handbags, 36.4ms\n",
            "Speed: 3.5ms preprocess, 36.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 4 backpacks, 4 handbags, 36.6ms\n",
            "Speed: 3.5ms preprocess, 36.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 4 backpacks, 3 handbags, 36.2ms\n",
            "Speed: 6.1ms preprocess, 36.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 backpacks, 1 handbag, 1 frisbee, 36.2ms\n",
            "Speed: 7.5ms preprocess, 36.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 backpacks, 3 handbags, 1 frisbee, 41.5ms\n",
            "Speed: 3.2ms preprocess, 41.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 backpacks, 3 handbags, 35.9ms\n",
            "Speed: 7.9ms preprocess, 35.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 3 handbags, 1 frisbee, 38.4ms\n",
            "Speed: 3.3ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 5 handbags, 1 frisbee, 36.2ms\n",
            "Speed: 3.4ms preprocess, 36.2ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 3 handbags, 1 tennis racket, 39.8ms\n",
            "Speed: 3.4ms preprocess, 39.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 6 handbags, 36.2ms\n",
            "Speed: 3.3ms preprocess, 36.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 4 handbags, 1 frisbee, 2 tennis rackets, 42.2ms\n",
            "Speed: 6.8ms preprocess, 42.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 4 handbags, 1 tennis racket, 37.4ms\n",
            "Speed: 3.5ms preprocess, 37.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 3 handbags, 1 frisbee, 1 tennis racket, 39.4ms\n",
            "Speed: 4.1ms preprocess, 39.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 5 handbags, 1 frisbee, 1 tennis racket, 38.6ms\n",
            "Speed: 3.7ms preprocess, 38.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 backpacks, 2 handbags, 1 frisbee, 2 tennis rackets, 38.4ms\n",
            "Speed: 3.1ms preprocess, 38.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 2 handbags, 1 tennis racket, 37.4ms\n",
            "Speed: 3.2ms preprocess, 37.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 4 handbags, 1 tennis racket, 35.0ms\n",
            "Speed: 3.3ms preprocess, 35.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 4 handbags, 37.1ms\n",
            "Speed: 3.1ms preprocess, 37.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 3 handbags, 35.4ms\n",
            "Speed: 3.2ms preprocess, 35.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 2 handbags, 35.1ms\n",
            "Speed: 3.1ms preprocess, 35.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 2 handbags, 36.4ms\n",
            "Speed: 3.5ms preprocess, 36.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 1 handbag, 38.8ms\n",
            "Speed: 3.2ms preprocess, 38.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 1 handbag, 35.1ms\n",
            "Speed: 3.2ms preprocess, 35.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 1 handbag, 35.1ms\n",
            "Speed: 3.3ms preprocess, 35.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 1 handbag, 35.3ms\n",
            "Speed: 6.5ms preprocess, 35.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 1 handbag, 35.1ms\n",
            "Speed: 3.1ms preprocess, 35.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 2 handbags, 34.5ms\n",
            "Speed: 5.0ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 2 handbags, 34.6ms\n",
            "Speed: 3.2ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 5 backpacks, 1 handbag, 35.2ms\n",
            "Speed: 3.5ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 4 backpacks, 2 handbags, 30.5ms\n",
            "Speed: 4.1ms preprocess, 30.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 7 backpacks, 1 handbag, 30.3ms\n",
            "Speed: 3.4ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 5 backpacks, 1 handbag, 1 clock, 30.8ms\n",
            "Speed: 3.2ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 6 backpacks, 1 handbag, 30.8ms\n",
            "Speed: 4.7ms preprocess, 30.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 1 handbag, 30.7ms\n",
            "Speed: 5.6ms preprocess, 30.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 1 handbag, 30.9ms\n",
            "Speed: 4.4ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 30.9ms\n",
            "Speed: 3.4ms preprocess, 30.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 4 backpacks, 1 handbag, 30.9ms\n",
            "Speed: 3.4ms preprocess, 30.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 4 backpacks, 1 suitcase, 30.3ms\n",
            "Speed: 3.2ms preprocess, 30.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 5 backpacks, 2 handbags, 30.5ms\n",
            "Speed: 3.2ms preprocess, 30.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 4 backpacks, 3 handbags, 30.8ms\n",
            "Speed: 4.8ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 backpacks, 2 handbags, 32.0ms\n",
            "Speed: 3.2ms preprocess, 32.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 4 backpacks, 2 handbags, 31.7ms\n",
            "Speed: 3.3ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 2 handbags, 32.4ms\n",
            "Speed: 3.2ms preprocess, 32.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 1 handbag, 32.0ms\n",
            "Speed: 3.2ms preprocess, 32.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 backpacks, 2 handbags, 31.7ms\n",
            "Speed: 3.4ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 1 handbag, 30.8ms\n",
            "Speed: 3.3ms preprocess, 30.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 backpacks, 1 handbag, 30.7ms\n",
            "Speed: 5.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 backpacks, 2 handbags, 29.5ms\n",
            "Speed: 3.2ms preprocess, 29.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 2 handbags, 31.3ms\n",
            "Speed: 3.3ms preprocess, 31.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 backpacks, 1 handbag, 30.4ms\n",
            "Speed: 3.9ms preprocess, 30.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 3 backpacks, 2 handbags, 30.8ms\n",
            "Speed: 3.3ms preprocess, 30.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 backpacks, 1 handbag, 33.6ms\n",
            "Speed: 3.2ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 backpacks, 32.5ms\n",
            "Speed: 3.0ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 5 backpacks, 1 handbag, 32.6ms\n",
            "Speed: 3.2ms preprocess, 32.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 backpacks, 1 handbag, 32.6ms\n",
            "Speed: 4.1ms preprocess, 32.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 4 backpacks, 1 handbag, 32.2ms\n",
            "Speed: 3.8ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 backpacks, 1 handbag, 30.7ms\n",
            "Speed: 4.4ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 5 backpacks, 1 handbag, 29.8ms\n",
            "Speed: 2.8ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 backpacks, 1 handbag, 30.6ms\n",
            "Speed: 2.9ms preprocess, 30.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 4 backpacks, 2 handbags, 30.4ms\n",
            "Speed: 5.2ms preprocess, 30.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 5 backpacks, 1 handbag, 30.7ms\n",
            "Speed: 4.3ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 backpacks, 1 handbag, 29.7ms\n",
            "Speed: 3.1ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 1 handbag, 1 frisbee, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 1 handbag, 1 suitcase, 1 frisbee, 30.1ms\n",
            "Speed: 3.2ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 1 handbag, 1 suitcase, 1 frisbee, 30.4ms\n",
            "Speed: 3.4ms preprocess, 30.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 backpacks, 1 handbag, 1 frisbee, 30.5ms\n",
            "Speed: 3.8ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 2 handbags, 1 frisbee, 30.4ms\n",
            "Speed: 3.5ms preprocess, 30.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 2 handbags, 1 frisbee, 30.7ms\n",
            "Speed: 4.8ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 backpacks, 1 handbag, 1 frisbee, 30.1ms\n",
            "Speed: 3.2ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 4 backpacks, 2 handbags, 1 frisbee, 30.4ms\n",
            "Speed: 3.4ms preprocess, 30.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 2 handbags, 1 frisbee, 30.7ms\n",
            "Speed: 5.1ms preprocess, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "model = YOLO(\"yolov8x.pt\")\n",
        "\n",
        "distance_threshold = 100\n",
        "min_people_in_crowd = 3\n",
        "\n",
        "video_path = \"input_video.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "output_video_path = \"output_video.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, 30.0, (frame_width, frame_height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret or frame_count >= 1000:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    results = model(frame)\n",
        "    people_boxes = []\n",
        "\n",
        "    for result in results:\n",
        "        boxes = result.boxes.xyxy\n",
        "        confidences = result.boxes.conf\n",
        "        class_ids = result.boxes.cls\n",
        "\n",
        "        for i in range(len(boxes)):\n",
        "            x1, y1, x2, y2 = map(int, boxes[i][:4])\n",
        "            conf = confidences[i]\n",
        "            class_id = int(class_ids[i])\n",
        "\n",
        "            if class_id == 0 and conf > 0.1:\n",
        "                people_boxes.append((x1, y1, x2, y2))\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    crowd_groups = []\n",
        "\n",
        "    for i, box1 in enumerate(people_boxes):\n",
        "        group = {i}\n",
        "\n",
        "        for j, box2 in enumerate(people_boxes):\n",
        "            if i == j:\n",
        "                continue\n",
        "\n",
        "            center1 = ((box1[0] + box1[2]) // 2, (box1[1] + box1[3]) // 2)\n",
        "            center2 = ((box2[0] + box2[2]) // 2, (box2[1] + box2[3]) // 2)\n",
        "            distance = np.sqrt((center1[0] - center2[0]) ** 2 + (center1[1] - center2[1]) ** 2)\n",
        "\n",
        "            if distance < distance_threshold:\n",
        "                group.add(j)\n",
        "\n",
        "        if len(group) >= min_people_in_crowd:\n",
        "            crowd_groups.append(group)\n",
        "\n",
        "    for group in crowd_groups:\n",
        "        for idx in group:\n",
        "            x1, y1, x2, y2 = people_boxes[idx]\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd4ty5O28RzY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}